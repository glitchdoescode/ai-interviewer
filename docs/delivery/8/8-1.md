# 8-1 Create Gemini Live API Audio Stream Adapter

[Back to task list](./tasks.md)

## Description

Implement a real-time audio streaming adapter using Gemini Live API that replaces the current sequential STT->LLM->TTS flow. This adapter will be based on the `geminicode1.py` implementation and provide bidirectional audio streaming with silent context injection capabilities.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-01-27 10:30:00 | Created | N/A | Proposed | Task file created | AI_Agent |
| 2025-01-27 15:00:00 | Status Change | Proposed | Agreed | Task approved for implementation | User |
| 2025-01-27 15:05:00 | Status Change | Agreed | InProgress | Started implementation of GeminiLiveAudioAdapter | AI_Agent |
| 2025-01-27 15:30:00 | Status Change | InProgress | Review | Implementation completed, ready for review | AI_Agent |
| 2025-01-27 15:35:00 | Status Change | Review | Done | Implementation approved and completed | User |

## Requirements

### Functional Requirements
1. **Real-time Audio Streaming**
   - Implement bidirectional audio streaming using Gemini Live API
   - Support continuous audio input/output without turn-based conversation
   - Handle audio format conversion (PCM 16kHz input, 24kHz output)

2. **Context Injection**
   - Support silent context injection without interrupting conversation
   - Inject interview metadata (job_role, seniority_level, stage, etc.)
   - Update context dynamically as interview progresses

3. **Integration Points**
   - Expose async methods for starting/stopping audio sessions
   - Provide callback mechanism for audio responses
   - Support context updates from external LangGraph adapter

### Technical Requirements
1. **Base Implementation**: Use `geminicode1.py` BatchedContextAudioLoop as foundation
2. **Audio Libraries**: PyAudio for local audio handling
3. **API Integration**: Google GenAI client for Gemini Live API
4. **Async Architecture**: Full async/await pattern for non-blocking operations

## Implementation Plan

### Phase 1: Core Audio Stream (Priority: Critical)
```python
# File: ai_interviewer/services/gemini_live_adapter.py

class GeminiLiveAudioAdapter:
    def __init__(self, api_key: str, interview_context: Dict[str, Any]):
        self.api_key = api_key
        self.interview_context = interview_context
        self.session = None
        self.running = False
        self.audio_callbacks = []
        
    async def start_session(self, initial_prompt: str):
        """Start Gemini Live API session with initial context"""
        
    async def inject_context(self, context_update: Dict[str, Any]):
        """Silently inject context without interrupting conversation"""
        
    async def stop_session(self):
        """Clean shutdown of audio session"""
        
    def add_audio_callback(self, callback: Callable):
        """Register callback for audio responses"""
```

### Phase 2: Context Management
- Implement silent context injection using system messages
- Format interview context into conversation-appropriate text
- Handle context batching to avoid API rate limits

### Phase 3: Integration Hooks
- Create event system for interview stage transitions
- Implement callback mechanism for LangGraph integration
- Add session persistence hooks for MongoDB storage

## Verification

### Unit Tests
1. **Audio Stream Initialization**
   - Test Gemini Live API connection establishment
   - Verify audio format handling
   - Test graceful error handling for API failures

2. **Context Injection**
   - Test silent context injection without audio interruption
   - Verify context formatting and delivery
   - Test context update batching

3. **Session Management**
   - Test session start/stop lifecycle
   - Verify proper cleanup on errors
   - Test concurrent session handling

### Integration Tests
1. **Audio Quality**
   - Record 30-second audio sample and verify output quality
   - Test audio latency measurements (<2 seconds)
   - Verify no audio dropouts during context injection

2. **Context Preservation**
   - Test interview context injection during active conversation
   - Verify context updates don't interrupt ongoing speech
   - Test context persistence across session reconnections

## Files Modified

- `ai_interviewer/services/gemini_live_adapter.py` (new)
- `ai_interviewer/services/__init__.py` (updated)
- `requirements.txt` (updated - add google-genai dependency)
- `tests/unit/services/test_gemini_live_adapter.py` (new)
- `tests/integration/test_audio_streaming.py` (new)

## Test Plan

### Environment Setup
- Test environment with microphone and speaker access
- Mock Gemini Live API for unit tests
- Real API connection for integration tests

### Test Scenarios
1. **Happy Path**: Start session → inject context → stream audio → receive responses → stop session
2. **Error Handling**: API connection failures, audio device errors, context injection failures
3. **Performance**: Latency measurements, memory usage during long sessions
4. **Concurrency**: Multiple session handling, race condition testing

### Success Criteria
- Audio latency consistently <2 seconds
- Context injection works without audio interruption
- No memory leaks during 30+ minute sessions
- Graceful error handling and recovery
- TypeScript compilation passes without errors 